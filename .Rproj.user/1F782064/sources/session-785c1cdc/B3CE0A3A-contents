# load libraries
library(tidyverse)
library(brms)

# load data
setwd("~/McGill/Eval2/scripts/PIN-PEN-merger/scripts")
filename <- "../data/spade-Raleigh_formants.csv"
raleigh_raw <- read.csv(filename)

# normalization and filtering
raleigh <- raleigh_raw %>%
  group_by(speaker) %>% 
  mutate(zF1 = as.numeric(scale(F1)), zF2 = as.numeric(scale(F2))) %>% # lobanov normalization
  filter(UnisynPrimStressedVowel1 %in% c('i', 'e') & UnisynPrimStressedVowel1==unisynPrimStressedVowel2_sca) %>% # unisyn vowel is i or e, and is 1 is same as 2
  filter(syllable_stress == 1) %>% # keep only stressed syllables
  mutate(context = case_when(
    following_phone %in% c("B", "CH", "D", "DH", "F", "G", "HH", "JH", "K", "L", "P", "R", "S", "SH", "T", "TH", "V", "W", "Y", "Z", "ZH" ) ~ "oral", # oral consonants
    following_phone %in% c("N", "M") ~ "nasal", ## nasal consonants; note: NG not included
    TRUE ~ "other")) %>% 
  filter(context != "other") %>% # get rid of everything that isn't an oral or nasal consonant
  mutate(vowel = as.factor(UnisynPrimStressedVowel1))%>%
  droplevels()

raleigh$context <- factor(raleigh$context)
contrasts(raleigh$context) <- contr.helmert(2)

raleigh$vowel <- factor(raleigh$vowel)
contrasts(raleigh$vowel) <- contr.helmert(2)

# # sanity check: 
# xtabs(~phone_label, raleigh)
# 
# # phone_label
# # AA1   AE1   AY1   EH1   EY1   IH1   IY1 
# # 2   977    31 23867    10 24482    10 
# 
# filter(raleigh, phone_label =='AA1') %>% ungroup() %>% count(word) # ENCLAVES
# filter(raleigh, phone_label =='AE1') %>% ungroup() %>% count(word) # YEAH, KEPT: get rid of YEAH!!!
# filter(raleigh, phone_label =='AY1') %>% ungroup() %>% count(word) # LIVED
# filter(raleigh, phone_label =='EY1') %>% ungroup() %>% count(word) # MEGAN, REGULAR could be subject to BEG-raising (SPECIALY should be fine)
# filter(raleigh, phone_label =='IY1') %>% ungroup() %>% count(word) # CHLORPYRIFOS, NISSAN, SHIT

# filter out "bad" words
bad_words <- c("ENCLAVES", "YEAH", "MEGAN", "REGULAR", "NISSAN")
raleigh <- raleigh %>% filter(!(word %in% bad_words)) %>% droplevels()

# # check ratios
# 
# xtabs(~following_phone, raleigh_raw)
# # M     N     
# # 28743 62721
# 
# xtabs(~following_phone, raleigh)
# # M     N   
# # 1461 11709
# 
# 1461/28743 # fraction of /m/ tokens kept
# # 0.05
# 
# 11709/62721 # fraction of /n/ tokens kept
# # 0.19
# 
# nrow(raleigh)/nrow(raleigh_raw) # fraction of tokens kept, total
# # 0.11

# save cleaned data
saveRDS(raleigh, "../data/raleigh_cleaned.rds")